{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "PSY 394U <b>Data Analytics with Python</b>, Spring 2018\n",
    "\n",
    "\n",
    "<img style=\"width: 400px; padding: 0px;\" src=\"https://github.com/sathayas/JupyterAnalyticsSpring2018/blob/master/images/Title_pics.png?raw=true\" alt=\"title pics\"/>\n",
    "\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align:center; font-size:40px; margin-bottom: 30px;\"><b> Corpora </b></p>\n",
    "\n",
    "<p style=\"text-align:center; font-size:18px; margin-bottom: 32px;\"><b>April 17, 2018</b></p>\n",
    "\n",
    "<hr style=\"height:5px;border:none\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Example corpora\n",
    "<hr style=\"height:1px;border:none\" />\n",
    "\n",
    "As you saw in the previous class, there are a number of corpora available in the **`book`** collection of **NLTK**. You can examine the list of texts with the **`fileids`** method associated with a corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<ListCorpus.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Gutenberg corpus\n",
    "from nltk.corpus import gutenberg\n",
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you know the document id, then you can access the document using **`raw`**, **`words`**, or **`sents`** methods. Here are examples from the corpus **`movie_reviews`**, a collection of positive and negative movie reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "director luis mandoki's last film was the superb , serious 1994 drama \" when a man loves a woman , \" but his luck has ultimately run out with his latest picture , \" message in a bottle , \" which is the worst type of romance , a movie that tugs so relentlessly and violently at the heartstrings that i\n"
     ]
    }
   ],
   "source": [
    "# Movie reviews\n",
    "from nltk.corpus import movie_reviews as mr\n",
    "#print(mr.fileids())\n",
    "print(mr.raw('neg/cv981_16679.txt')[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glory--starring matthew broderick , denzel washington , and morgan freeman--is the true story of the 54th regiment of massachusetts , the first black fighting unit recruited by the north during the civil war . \n",
      "broderick plays robert gould shaw , the young white officer who led the black soldiers in\n"
     ]
    }
   ],
   "source": [
    "print(mr.raw('pos/cv997_5046.txt')[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some corpora consist of multiple categories. You can examine such categories by the **`categories`** method associated with a corpus. Here is an example with the Brown corpus, a collection of text available from Brown University."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n"
     ]
    }
   ],
   "source": [
    "# Brown corpus\n",
    "from nltk.corpus import brown\n",
    "print(brown.categories())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can examine only those files under a certain category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ca01', 'ca02', 'ca03', 'ca04', 'ca05', 'ca06', 'ca07', 'ca08', 'ca09', 'ca10', 'ca11', 'ca12', 'ca13', 'ca14', 'ca15', 'ca16', 'ca17', 'ca18', 'ca19', 'ca20']\n"
     ]
    }
   ],
   "source": [
    "print(brown.fileids(['news'])[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at one of the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "For/in-hl crucial/jj-hl encounter/nn-hl \n",
      "One/cd of/in the/at initial/jj questions/nns put/vbn to/in President/nn-tl Kennedy/np at/in his/pp$ first/od news/nn conference/nn last/ap January/np was/bedz about/in his/pp$ attitude/nn toward/in a/at meeting/nn with/in Premier/nn-tl Khrushchev/np ./.\n",
      "Mr\n"
     ]
    }
   ],
   "source": [
    "print(brown.raw(fileids='ca34')[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this text is already tagged with POS tags (see symbols after each slash(/)). \n",
    "\n",
    "Here is another categorized corpus **`reuters`**, a collection of news stories by **Reuters**. Stories are categorized according to their topic(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn', 'cotton', 'cotton-oil', 'cpi', 'cpu', 'crude', 'dfl', 'dlr', 'dmk', 'earn', 'fuel', 'gas', 'gnp', 'gold', 'grain', 'groundnut', 'groundnut-oil', 'heat', 'hog', 'housing', 'income', 'instal-debt', 'interest', 'ipi', 'iron-steel', 'jet', 'jobs', 'l-cattle', 'lead', 'lei', 'lin-oil', 'livestock', 'lumber', 'meal-feed', 'money-fx', 'money-supply', 'naphtha', 'nat-gas', 'nickel', 'nkr', 'nzdlr', 'oat', 'oilseed', 'orange', 'palladium', 'palm-oil', 'palmkernel', 'pet-chem', 'platinum', 'potato', 'propane', 'rand', 'rape-oil', 'rapeseed', 'reserves', 'retail', 'rice', 'rubber', 'rye', 'ship', 'silver', 'sorghum', 'soy-meal', 'soy-oil', 'soybean', 'strategic-metal', 'sugar', 'sun-meal', 'sun-oil', 'sunseed', 'tea', 'tin', 'trade', 'veg-oil', 'wheat', 'wpi', 'yen', 'zinc']\n"
     ]
    }
   ],
   "source": [
    "# Reuter corpus\n",
    "from nltk.corpus import reuters\n",
    "print(reuters.categories())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a story on housing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test/18911', 'test/19875', 'test/20106', 'test/20116', 'training/1035', 'training/1036', 'training/11170', 'training/11665', 'training/29', 'training/3105', 'training/3708', 'training/3720', 'training/3723', 'training/3898', 'training/5883', 'training/5886', 'training/6000', 'training/6067', 'training/6197', 'training/9615']\n"
     ]
    }
   ],
   "source": [
    "print(reuters.fileids(['housing']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U.S. HOUSING COMPLETIONS FELL 0.2 PCT IN JAN\n",
      "  Completions of new homes fell 0.2\n",
      "  pct in January to a seasonally adjusted rate of 1.884 mln units\n",
      "  from 1.888 mln in December, the Commerce Department said.\n",
      "      The January fall came after a strong 6.4 pct rise from\n",
      "  November's rate of 1.774 mln u\n"
     ]
    }
   ],
   "source": [
    "print(reuters.raw(fileids='training/3720')[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Creating own corpus\n",
    "<hr style=\"height:1px;border:none\" />\n",
    "\n",
    "Say, you have a number of text files to form your own corpus. You can load your documents as a corpus so that you can use methods associated with a corpus in NLTK. This can be done by the function **`PlaintextCorpusReader`** under **`nltk.corpus`**. This function lets you treat a directory of text files as a corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<OwnCorpus.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "# creating own corpus\n",
    "corpus_root = 'SentimentReviews'\n",
    "reviews = PlaintextCorpusReader(corpus_root, \".*\\.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The directory **`SentimentReviews`** contains text files of reviews from *Amazon*, *IMDB*, and *Yelp*. Each review is followed by a number (0 for negative and 1 for positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazon_cells_labelled.txt', 'imdb_labelled.txt', 'readme.txt', 'yelp_labelled.txt']\n"
     ]
    }
   ],
   "source": [
    "# contents of the corpus\n",
    "print(reviews.fileids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read the raw data,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow... Loved this place.\t1\n",
      "Crust is not good.\t0\n",
      "Not tasty and the texture was just nasty.\t0\n",
      "Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.\t1\n",
      "The selection on the menu was great and so were the prices.\t1\n",
      "Now I am getting angry and I want my damn pho.\t0\n",
      "Honeslt\n"
     ]
    }
   ],
   "source": [
    "print(reviews.raw('yelp_labelled.txt')[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can tokenize by words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wow', '...', 'Loved', 'this', 'place', '.', '1', 'Crust', 'is', 'not', 'good', '.', '0', 'Not', 'tasty', 'and', 'the', 'texture', 'was', 'just', 'nasty', '.', '0', 'Stopped', 'by', 'during', 'the', 'late', 'May', 'bank', 'holiday', 'off', 'Rick', 'Steve', 'recommendation', 'and', 'loved', 'it', '.', '1', 'The', 'selection', 'on', 'the', 'menu', 'was', 'great', 'and', 'so', 'were', 'the', 'prices', '.', '1', 'Now', 'I', 'am', 'getting', 'angry', 'and', 'I', 'want', 'my', 'damn', 'pho', '.', '0', 'Honeslty', 'it', 'didn', \"'\", 't', 'taste', 'THAT', 'fresh', '.)', '0', 'The', 'potatoes', 'were']\n"
     ]
    }
   ],
   "source": [
    "print(reviews.words('yelp_labelled.txt')[:80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. WordNet\n",
    "<hr style=\"height:1px;border:none\" />\n",
    "\n",
    "The corpus **WordNet** is a collection of synonyms with dictionary-like functions. For example, let's take a look at synonyms of the word *\"program\"*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<WordNet.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('plan.n.01'), Synset('program.n.02'), Synset('broadcast.n.02'), Synset('platform.n.02'), Synset('program.n.05'), Synset('course_of_study.n.01'), Synset('program.n.07'), Synset('program.n.08'), Synset('program.v.01'), Synset('program.v.02')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# synset\n",
    "syns = wn.synsets('program')\n",
    "print(syns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are different collections of synonyms of the word *program*. Since *\"program\"* can have many different meanings, we can examine the meaning of these **`synset`**'s. The definition is available with the **`definition`** method associated with each `synset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('plan.n.01') :a series of steps to be carried out or goals to be accomplished\n",
      "Synset('program.n.02') :a system of projects or services intended to meet a public need\n",
      "Synset('broadcast.n.02') :a radio or television show\n",
      "Synset('platform.n.02') :a document stating the aims and principles of a political party\n",
      "Synset('program.n.05') :an announcement of the events that will occur as part of a theatrical or sporting event\n",
      "Synset('course_of_study.n.01') :an integrated course of academic studies\n",
      "Synset('program.n.07') :(computer science) a sequence of instructions that a computer can interpret and execute\n",
      "Synset('program.n.08') :a performance (or series of performances) at a public presentation\n",
      "Synset('program.v.01') :arrange a program of or for\n",
      "Synset('program.v.02') :write a computer program\n"
     ]
    }
   ],
   "source": [
    "# definition for each meaning\n",
    "for isyn in syns:\n",
    "    print(isyn, ':', end='')\n",
    "    print(isyn.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say, we are interested in a \"program\" for a computer. So **`synset('program.n.07')`** is the most appropriate. You can examine its synonyms by the **`lemma_names`** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['program', 'programme', 'computer_program', 'computer_programme']\n"
     ]
    }
   ],
   "source": [
    "# synnonyms for the computer program\n",
    "print(wn.synset('program.n.07').lemma_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also take a look at the synonyms of a \"program\" for TV or radio (i.e., `synset('program.n.02')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['broadcast', 'program', 'programme']\n"
     ]
    }
   ],
   "source": [
    "# synnonyms for a broadcasting program\n",
    "print(wn.synset('broadcast.n.02').lemma_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another example of a *synset*. This time, we will examine the word **\"plan\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('plan.n.01') :a series of steps to be carried out or goals to be accomplished\n",
      "Synset('design.n.02') :an arrangement scheme\n",
      "Synset('plan.n.03') :scale drawing of a structure\n",
      "Synset('plan.v.01') :have the will and intention to carry out some action\n",
      "Synset('plan.v.02') :make plans for something\n",
      "Synset('plan.v.03') :make or work out a plan for; devise\n",
      "Synset('design.v.04') :make a design of; plan out in systematic, often graphic form\n"
     ]
    }
   ],
   "source": [
    "# another synset\n",
    "syns = wn.synsets('plan')\n",
    "for isyn in syns:\n",
    "    print(isyn, ':', end='')\n",
    "    print(isyn.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synonyms for the first meaning as a noun (`synset('plan.n.01')`) are:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plan', 'program', 'programme']\n"
     ]
    }
   ],
   "source": [
    "# synnonyms\n",
    "print(wn.synset('plan.n.01').lemma_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word similarity\n",
    "\n",
    "The **WordNet** also has a number of methods to quantify the similarity between two different words. If the similarity is close to 1, two words are similar, if the similarity is close to 0, the words are not similar.\n",
    "\n",
    "For example, the word \"program\" (for a computer) has a similar meaning to the word \"code\" (for a computer). The similarity score between the words is determined by the **`wup_similairty`** method for one of the words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n"
     ]
    }
   ],
   "source": [
    "# similarity\n",
    "synsProgram = wn.synset('program.n.07')\n",
    "synsCode = wn.synset('code.n.03')\n",
    "print(synsProgram.wup_similarity(synsCode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, the word \"broadcast\" (a synonym of \"program\", as in TV programs) is not very similar to the word \"code\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "synsBroadcast = wn.synset('broadcast.n.02')\n",
    "synsCode = wn.synset('code.n.03')\n",
    "print(synsBroadcast.wup_similarity(synsCode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "1. **Car and vehicle**. Calculate the similarity scores for all possible meanings of the words **car** and **vehicle**. Then identify the combination of meanings that yield the highest similarity score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
