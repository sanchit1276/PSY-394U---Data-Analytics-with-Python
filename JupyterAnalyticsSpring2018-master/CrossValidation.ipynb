{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "PSY 394U <b>Data Analytics with Python</b>, Spring 2018\n",
    "\n",
    "\n",
    "<img style=\"width: 400px; padding: 0px;\" src=\"https://github.com/sathayas/JupyterAnalyticsSpring2018/blob/master/images/Title_pics.png?raw=true\" alt=\"title pics\"/>\n",
    "\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align:center; font-size:40px; margin-bottom: 30px;\"><b> Feature selection & cross validation </b></p>\n",
    "\n",
    "<p style=\"text-align:center; font-size:18px; margin-bottom: 32px;\"><b>March 1, 2018</b></p>\n",
    "\n",
    "<hr style=\"height:5px;border:none\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feature selection\n",
    "<hr style=\"height:1px;border:none\" />\n",
    "\n",
    "We talked about the curse of dimensionality in our previous class. To get around it, we can reduce the dimensionality of the data (e.g., PCA). Anther approach is to eliminate features that are not associated with the target, and to retain only those features that likely contribute classification of a data set, the process known as **feature selection**. There are a number of approaches for feature selection. The ones I present here are based on statistical principles, and may be familiar to most of you.\n",
    "\n",
    "## Example: cryotherapy data\n",
    "\n",
    "To demonstrate feature selection, we will examine the cryotherapy data again (**`Cryotherapy.csv`**). As you recall, there are 6 features in this data set, of which two are categorical (**`Sex`** and **`Type`**) and four are continuous (**`Age`**, **`Time`**, **`NumWarts`**, and **`Area`**). Here, we load the data and separate categorical and continuous features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<CryoFeatures.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "\n",
    "# loading the data\n",
    "CryoData = pd.read_csv('Cryotherapy.csv')\n",
    "\n",
    "# features, categorical and continuous\n",
    "xCat = CryoData[['Sex','Type']]\n",
    "xCont = CryoData[['Age','Time','NumWarts','Area']]\n",
    "y = CryoData.Success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features\n",
    "\n",
    "The association between a categorical feature and the target (a categorical variable) can be assessed by a $\\chi^2$ test. The function **`chi2`** in **`sklearn.feature_selection`** can perform a $\\chi^2$ test between each feature and the target. The `chi2` function requires two input parameters, the feature data array and the target labels. It returns 2 parameters; the first output parameter is an array of $\\chi^2$ test statistics and the second output parameter is an array of corresponding p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73684818 0.00149219]\n"
     ]
    }
   ],
   "source": [
    "# categorical features\n",
    "chiStat, chiP = chi2(xCat,y)\n",
    "print(chiP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you can see that the feature `Type` is highly associated with the target, but not `Sex`.\n",
    "\n",
    "### Continuous features\n",
    "\n",
    "The association between a continuous feature and the target (a categorical variable) can be assessed by an ANOVA. In particular, an ANOVA F-test examine whether there is any mean difference in the feature of interest between target classes. The function **`f_classif`** in **`sklearn.feature_selection`** can perform an ANOVA F-test between each feature and the target. The `f_classif` function requires two input parameters, the feature data array and the target labels. It returns 2 parameters; the first output parameter is an array of ANOVA F-test statistics and the second output parameter is an array of corresponding p-values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.26472884e-08 2.72305388e-12 4.63372617e-01 7.45913301e-02]\n"
     ]
    }
   ],
   "source": [
    "# continuous features\n",
    "fStat, fP = f_classif(xCont,y)\n",
    "print(fP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like only `Age` and `Time` are significantly associated with the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cross validation\n",
    "<hr style=\"height:1px;border:none\" />\n",
    "\n",
    "## What is cross validation?\n",
    "\n",
    "We have used a training data set to generate a classifier and a testing data set to evaluate the performance of the resulting classifier. But how can we be sure that the classifiation results are consistent regardless of which training and testing data sets to use? One way to verify is to generate multiple training and testing data sets and evaluate classification performance multiple times. **Cross validation** is one such approach. In a **k-fold** cross validation, the data set is divided into k equal sizes. In the first iteration, the first of the k segments is used as the testing data set, while the remaining k-1 segments are used as the training data set. In the second iteration, the second segment is used as the testing data set. And so on. Here is a schematic of 5-fold cross validation.\n",
    "\n",
    "<img style=\"width: 500px; padding: 0px;\" src=\"https://github.com/sathayas/JupyterAnalyticsSpring2018/blob/master/images/CV_5fold.png?raw=true\" alt=\"5-fold cross validation\"/>\n",
    "\n",
    "As you can see, a k-fold validation enables the classification performance evaluation k times. \n",
    "\n",
    "## Example: iris data\n",
    "\n",
    "Let's perform a 5-fold cross validation on the iris data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<IrisCV.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# Loading the iris data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:,[0,3]]  # sepal length and petal width only\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to define a classifier object to be examined by the cross validation. Here, we use a k nearest neighbor (kNN) classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defining the nearest neighbor classifier\n",
    "kNN = KNeighborsClassifier(5, weights='uniform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the actual cross validation, we can use the **`cross_val_score`** function in **`sklearn.model_selection`**. In `cross_val_score`, we need to provide the classifier object as an input parameter, as well as the data matrix for the features and the target variable. The number of *folds* can be specified by the parameter **`cv`**. Then `cross_val_score` splits the data into k-folds and perform a classifier analysis (building and evaluating a classifier) k times automatically. The results can be returned as the **accuracy** score. The **accuracy** is defined by the proportion of observations correctly classified, compared to all available observations. Or, in a confusion matrix, the total number of observation along the main diagonal, divided by the total number of observations in a testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93333333 0.96666667 0.93333333 0.93333333 1.        ]\n",
      "0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "# 5-fold cross validation\n",
    "scores = cross_val_score(kNN, X, y, cv=5)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the performance of this classifier seems consistent regardless of training & testing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: cryotherapy data\n",
    "\n",
    "We also perform a 5-fold cross validation on the cryotherapy data. Here, we only focus on two continuous features, namely **`Age`** and **`Time`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<CryoCV.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "# loading the data\n",
    "CryoData = pd.read_csv('Cryotherapy.csv')\n",
    "\n",
    "# Creating the data set\n",
    "X = np.array(CryoData.loc[:,['Age','Time']])\n",
    "y = np.array(CryoData.Success)\n",
    "targetNames = ['Failure', 'Success']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification on this data set is somewhat tricky because features have to be standardized before the analysis. Standardization has to occur every time after a training set is created, and must be applied to the corresponding testing data set. In order to implement this, we combine the standardization transformation object and the classifier object into a single object using the function **`make_pipeline`** under **`sklearn.pipeline`**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A pipeline of stadardization and kNN classifier\n",
    "kNN = make_pipeline(StandardScaler(), \n",
    "                    KNeighborsClassifier(15, weights='uniform'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `StandardScalar` transformation object is defined first, followed by the kNN classifier with k=15 and **`weights='uniform`**. The resulting pipeline object can be used in the *`cross_val_score`*  under `sklearn.pipeline.`*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94736842 0.84210526 1.         0.82352941 0.88235294]\n"
     ]
    }
   ],
   "source": [
    "# 5-fold cross validation\n",
    "scores = cross_val_score(kNN, X, y, cv=5)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the accuracy scores differ tremendously "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "1. **`Seed data, cross validation`**. For this exercise, the features and target data are loaded in  **`SeedCV.py`**. Perform a 5-fold cross validation with k=15. Print out the scores resulting from this classifier. Note that the data needs to be standardized before used in a classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Choosing parameters\n",
    "<hr style=\"height:1px;border:none\" />\n",
    "\n",
    "As you have seen before, most classifiers require some sort of fine tuning of parameters to adjust for different data sets. One way to find an optimal parameter(s) is to perform cross validation with different values for the parameter, and choose the parameter that produces the best results. \n",
    "\n",
    "## Example: iris data\n",
    "\n",
    "If there is just one parameter to be adjusted, then you can write a simple program to learn a classifier with different parameter values. For example, in our iris data example,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<IrisGridSearchKNN.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Loading the iris data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:,[0,3]]  # sepal length and petal width only\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to use a k nearest neighbor classifier. What is the optimal value of k for our data? We can perform cross validation with different values of k, and record the mean accuracy score for each value of k. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loop over k\n",
    "meanScores = []\n",
    "for k in range(5,20,2):\n",
    "    # defining the nearest neighbor classifier\n",
    "    kNN = KNeighborsClassifier(k, weights='uniform')\n",
    "\n",
    "    # 5-fold cross validation\n",
    "    scores = cross_val_score(kNN, X, y, cv=5)\n",
    "    meanScores.append(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can plot the mean score against k to see what value of k we should use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VfWd//HXJyGQsIYlREiARAUUAQEDKri0Wis6VhBH\nq2MFAhbtYm2nZYp2ZmpnfjMy2k5LO7XWKotLdbAFS1srtTjVukKQXUEohCXsQlgTsn1+f9yjjSHL\nxXBz7s19Px+P+8g933PO5X3hcj8553y/32PujoiIyCeVEnYAERFJbCokIiLSLCokIiLSLCokIiLS\nLCokIiLSLCokIiLSLCokIiLSLCokIiLSLCokIiLSLG3CDtASevTo4Xl5eWHHEBFJKMuXL9/v7llN\nbZcUhSQvL4+ioqKwY4iIJBQz2xrNdjq1JSIizaJCIiIizaJCIiIizaJCIiIizaJCIiIizRLTXltm\nNhaYBaQCj7n7zDrruwKzgbOAcmCKu68N1mUCjwGDAQ/WvWlm3YD/BfKAYuBmdz8Yy/eRCJ5fUcJD\nizews7SM3pkZTL96IOOH54Qdq16JlFVEmhazIxIzSwV+ClwDDAJuNbNBdTa7D1jp7kOBiUSKzodm\nAS+6+znA+cB7QfsMYIm79weWBMtJ7fkVJdy7YA0lpWU4UFJaxr0L1vD8ipKwo50kkbKKSHRieUQy\nCtjk7psBzOxZYBzwbq1tBgEzAdx9vZnlmVk2kaOTy4DJwboKoCLYZxzwqeD5PODPwLdj+D7i3kOL\nN1BWWf2xtrLKav7l+bVs3nc0pFT1m/N6cb1ZH1q8QUclIgkqloUkB9hea3kHcGGdbVYBE4C/mNko\noB+QC1QD+4A5ZnY+sBy4x92PAdnuvivYfzeQXd8fbmbTgGkAffv2PS1vKF7tLC2rt/3IiSp+8n+b\nWjhN49zrb2/oPYhI/At7ZPtMYJaZrQTWACuIFJE2wAjgbnd/28xmETmF9S+1d3Z3N7N6v5rc/VHg\nUYCCgoIGvr5ah07pbThcXnVSe05mBq/PuCKERA0bM/NlSuopGr0zM0JIIyKnQyx7bZUAfWot5wZt\nH3H3w+5e6O7DiFwjyQI2Ezl62eHubweb/opIYQHYY2a9AIKfe2P3FuLfolU7OVxeRarZx9oz0lKZ\nfvXAkFI1bPrVA8lISz2p/baLWvdRo0hrFstCsgzob2b5ZtYWuAVYVHsDM8sM1gHcAbwaFJfdwHYz\n+/Cb8Er+dm1lETApeD4J+E0M30Nce2vzB3xr/ipG5Xfjv24cQk5mBkbkSOSBCUPi8prD+OE5PDDh\nb1mzO7ejc3oqT765lV2HdHpLJBGZN3TS+nS8uNm1wI+IdP+d7e7/YWZ3Abj7I2Z2MZEL5g6sA6Z+\n2JXXzIYR6f7blshRSqG7HzSz7sB8oC+wlUj33wON5SgoKPDWNmnjxj1HuPFnb9Czczq/vms0Xdqn\nhR3pE3t352Fu/vmb5HbN4Lm7LqZTeuK+F5HWxMyWu3tBk9vFspDEi9ZWSPYcLmfCw29QUV3Dwi+P\nJrdr+7AjNdtfNu6jcM4yLjqzO7Mnj6RtG42VFQlbtIVE/1sTzNETVRTOWUbp8QrmTB7ZKooIwKX9\ns5h541Be27SfGQtWkwy/4Ii0FmH32pJTUFldw5eeWs6GPUeYPXkkg3O6hB3ptPr7C3LZWVrGf7/0\nPjmZGXzzs/HXWUBETqZCkiDcnfsWrOEvG/fz4I1DuXxAkzctS0h3X3E2O0vL+MnLm+idmcGto9Sb\nSyTeqZAkiFlLNvLc8h3cc2V/bh7Zp+kdEpSZ8e/jB7PrUDn//PxazuiSzqcH9gw7log0QtdIEsD8\nou386E8buemCXL7+mf5hx4m5tNQUHr5tBOf26sRXnn6HNTsOhR1JRBqhQhLnXnl/H/cuWMOl/Xvw\nnxOGYHUGHrZWHdq1YfbkkXRt35bCucvYfuB42JFEpAEqJHFsbckhvvzUcgZkd+Lh20aQlppc/1w9\nO6Uzb8pIKqtrmDRnKaXHK5reSURaXHJ9MyWQktIypsxdRpeMNOYWjkzaQXpn9+zELyYWsONAGV98\noojyOjMHi0j4VEji0KHjlUyevZSyymrmThlFduf0sCOFalR+N/778+ezrPgg35y/ipoajTERiSfq\ntRVnTlRVM+3JIrZ+cJx5U0YxILtT2JHiwnVDe7OrtJz/eOE9enVJ55+vq3uPNBEJiwpJHKmpcb71\n3Gre3nKAWbcM4+KzuocdKa7ccWk+JaVlPPbaFnK6ZlA4Jj/sSCKCCklc+a/F6/ntqp3MuOYcxg2L\nv5l7w2Zm/Mt1g9h1qIx/+9279OqSztjBvcKOJZL0dI0kTjzxZjE/f2Uzt1/UjzsvOzPsOHErNcWY\ndctwhvfJ5J5nV7J8a6MTP4tIC1AhiQN/XLeb+xet4zPnZnP/9eclzViRTyo9LZXHJo2kd2YGd8wr\nirv70oskGxWSkK3YdpCvPbuCIbmZ/OTW4aSmqIhEo1uHtswtHEmKGZPnLGP/0RNhRxJJWiokISre\nf4yp84rI7pzO45MKyGh78i1opWH9unfg8ckj2XuknKlzl3G84uT71otI7KmQhOSDoyeYPGcpAHML\nR9GjY7uQEyWmYX0y+cmtI1hTcoi7f7mCquqasCOJJB0VkhCUVVQzdV4Ruw6V89ikAvJ7dAg7UkK7\nalA23xs3mCXr9/LdRet0UyyRFqbuvy2susb52rMrWLWjlJ/ddgEj+nYNO1KrcPtF/Sg5WMYjr/yV\nnK4ZfPlTZ4cdSSRpqJC0IHfn3367jpfe3cP3rj+PsYPPCDtSq/JPVw9kZ2kZD764gd5dMhg/XGNx\nRFqCCkkL+sVfNjPvza1Mu+xMJo3OCztOq5OSYjx001D2Hiln+q9W0bNTO0af3SPsWCKtnq6RtJBF\nq3byny+s57qhvZgx9pyw47Ra7dqk8vPbI9ed7nxyORt2Hwk7kkirp0LSAt7a/AHfmr+KUfnd+P5N\n55OisSIx1SUjjTmFo2jfLpXJc5ay+1B52JFEWjUVkhjbuOcI054oom/39jx6+wWkp2msSEvIycxg\n9uSRHC6rZPKcpRwprww7kkirpUISQ3sPlzN5zjLapaUyt3Akme3bhh0pqZzXuws/+8IFbNp7lC89\n9Q4VVRpjIhILKiQxcvREFYVzl3HweAVzJo8kt2v7sCMlpcsGZPHAhCG8tmk/Mxas1hgTkRhQr60Y\nqKyu4ctPv8P63Ud4fFIBg3O6hB0pqd1U0IedpeX88E/vk5uZwT9+dmDYkURaFRWS08zd+c7CNbz6\n/j7+68YhfGpgz7AjCfC1K89mZ2kZP355E70yM7h1VN+wI4m0GjE9tWVmY81sg5ltMrMZ9azvamYL\nzWy1mS01s8G11hWb2RozW2lmRbXa7zezkqB9pZldG8v3cKp+vGQT84t28LUr+/P5kfqyihdmxv+7\nYTCXD8jin59fy/9t2Bt2JJFWI2aFxMxSgZ8C1wCDgFvNrO6Ntu8DVrr7UGAiMKvO+k+7+zB3L6jT\n/sOgfZi7vxCL/J/Ec0Xb+eGf3ufvL8jlG5/pH3YcqSMtNYWf3jaCc87oxFeefoc1Ow6FHUmkVYjl\nEckoYJO7b3b3CuBZYFydbQYBLwO4+3ogz8yyY5gpZl59fx/3LljDpf178MCEIbo5VZzq2K4NcyaP\npGv7thTOXcb2A8fDjiSS8GJZSHKA7bWWdwRtta0CJgCY2SigH5AbrHPgT2a23Mym1dnv7uB02Gwz\nq3fWQzObZmZFZla0b9++5r6XRq3beYgvPbWc/tmdePi2EaSlqjNcPOvZOZ15U0ZSUVXNpDlLKT1e\nEXYkkYQW9jfeTCDTzFYCdwMrgOpg3SXuPozIqbGvmNllQfvPgDOBYcAu4Af1vbC7P+ruBe5ekJWV\nFbM3UFJaRuGcZXTJSGNu4Ug6pafF7M+S0+fsnp34xcQCdhwo44tPFFFeWd30TiJSr1gWkhKgT63l\n3KDtI+5+2N0Lg4IxEcgCNgfrSoKfe4GFRE6V4e573L3a3WuAX3zYHoZDxyuZPHspZZXVzJ0yiuzO\n6WFFkU/gwjO784Obz2dZ8UG++dwqamo0xkTkk4hlIVkG9DezfDNrC9wCLKq9gZllBusA7gBedffD\nZtbBzDoF23QAPgusDZZ71XqJGz5sb2knqqqZ9mQRxR8c4+e3X8CA7E5hxJBm+tz5vbnv2nP4/epd\nPPCH98KOI5KQYjaOxN2rzOyrwGIgFZjt7uvM7K5g/SPAucA8M3NgHTA12D0bWBhcsG4D/NLdXwzW\nPWhmw4hcQykG7ozVe2hITY0z/bnVvL3lALNuGcboszRVeSL74qVnUnKwjF/8ZQu9MzMoHJMfdiSR\nhBLTAYlB19wX6rQ9Uuv5m8CAevbbDJzfwGvefppjnrIHF29g0aqdfHvsOYwbppsnJToz418/dx67\nDpXzb797l15d0hk7uFfTO4oIEP7F9oTz5JvFPPLKX/nCRX256/Izw44jp0lqivHjW4czrE8m9zy7\nkuVbD4QdSSRhqJCcgpfe3cN3F63jM+f25P7PnaexIq1Meloqj00soFeXdO6YV8TmfUfDjiSSEFRI\norRi20HufuYdhuRm8uNbh9NGY0Vape4d2zG3cBRmxuQ5y9h/9ETYkUTinr4No7D1g2PcMa+Inp3S\neXxSAe3baq7L1iyvRwcen1TA3iPlTJ27jOMVVWFHEolr+kZswPMrSnho8QZ2lpaRkmK0SzV+9aXR\n9OjYLuxo0gKG9+3KT24dwZ1PFnHTI29w8Hglu0rL6Z2ZwfSrBzJ+eHx2sqj9uY33rNJ6qJDU4/kV\nJdy7YA1lwWjn6hqnOsVYtb2U/B4dQk4nLeWqQdlMGJ7Dr9752zjaktIyZvx6NYfLK7kmznp2/WHt\nLv7z9+9RHtwJsqS0jHsXrAFQMZGYsmS4Y1xBQYEXFRU1vWFgzMyXKSktO6k9JzOD12dccTqjSZxr\n6LOQSPS5lU/KzJbXM/v6SXREUo+dDXxxNNQurVdj/+b/Pn5wg+vC8C/P1z/Jgz63EmsqJPXonZlR\n72+hvTMzQkgjYWros5CTmcHtF/ULIVHDHvnzX+vN2itTc8BJbKnXVj2mXz2QjLTUj7VlpKUy/Wrd\n6zvZJNJnob6sAPnd25MMp7AlPCok9Rg/PIcHJgwhJzMDI/Lb5wMThuiCZRJKpM9CfVmvOCeL1/96\ngEde2Rx2PGnFdLFdpBWrqXHu+d+V/HbVTmbdMkxzw8kp0cV2ESElxfj+TUPZe7icbz23ip6d0rn4\nrO5hx5JWRqe2RFq5dm1SeXRiAXndOzDtySLe33Mk7EjSyqiQiCSBLhlpzJ0yioy0VCbPXsqew+Vh\nR5JWRIVEJEnkZGYwp3Akh8oqmTxnGUfKK8OOJK2EColIEjmvdxce/sIFvL/nCF9++h0qq2vCjiSt\ngAqJSJK5fEAWD0wYwl827ufeBWs0xkSaTb22RJLQzQV92Flaxo/+tJHemRn841Un3fFaJGoqJCJJ\n6p4r+7OztIwfL9lITmY6nx/ZN+xIkqBUSESSlJnxHzcMYffhE9y3cC3ZndP51MCeYceSBKRrJCJJ\nLC01hYdvG8HA7E585el3WFtyKOxIkoBUSESSXMd2bZhbOJLM9m0pnLuM7QeOhx1JEowKiYjQs3M6\ncwtHcqKymsK5yzh0XGNMJHoqJCICQP/sTjw6sYBtHxzni08WcaKqOuxIkiBUSETkIxed2Z3v33w+\nS7cc4JvzV1FTozEm0jT12hKRj7n+/N7sKi3jgT+sp3dmBvdde27YkSTOqZCIyEmmXXYmJaVlPPrq\nZnIyM5g0Oi/sSBLHYnpqy8zGmtkGM9tkZjPqWd/VzBaa2WozW2pmg2utKzazNWa20syKarV3M7OX\nzGxj8LNrLN+DSDIyM777ufO4alA29/92HYvX7Q47ksSxJguJmWWb2eNm9odgeZCZTY1iv1Tgp8A1\nwCDgVjMbVGez+4CV7j4UmAjMqrP+0+4+rM4dumYAS9y9P7AkWBaR0yw1xfjxLcM5PzeTrz2zgne2\nHQw7ksSpaI5I5gKLgd7B8vvA16PYbxSwyd03u3sF8Cwwrs42g4CXAdx9PZBnZtlNvO44YF7wfB4w\nPoosIvIJZLRN5fFJBfTqks4d84rYsv9Y2JEkDkVTSHq4+3ygBsDdq4Bo+gXmANtrLe8I2mpbBUwA\nMLNRQD8gN1jnwJ/MbLmZTau1T7a77wqe7wbqLTxmNs3MisysaN++fVHEFZH6dO/YjrmFowCYPGcp\n+4+eCDmRxJtoCskxM+tO5IsdM7sIOF3zKMwEMs1sJXA3sIK/FalL3H0YkVNjXzGzy+ru7JH5r+vt\nn+juj7p7gbsXZGVlnaa4Iskpr0cHHptUwJ7D5UydV0RZhcaYyN9EU0j+EVgEnGVmrwNPEPnSb0oJ\n0KfWcm7Q9hF3P+zuhUHBmAhkAZuDdSXBz73AQiKnygD2mFkvgODn3iiyiEgzjejblVm3DGf1jlK+\n9uwKqjXGRAKNFhIzSwHSgcuB0cCdwHnuvjqK114G9DezfDNrC9xCpCDVfv3MYB3AHcCr7n7YzDqY\nWadgmw7AZ4G1wXaLgEnB80nAb6LIIiKnwdXnncH3rj+Pl97dw/2L1ummWAI0MY7E3WvM7KfuPhxY\ndyov7O5VZvZVIhfqU4HZ7r7OzO4K1j8CnAvMMzMPXv/D3mDZwEIz+zDjL939xWDdTGB+0HNsK3Dz\nqeQSkeaZeHEeJQfL+Pmrm8npmsFdl58VdiQJWTQDEpeY2Y3AAj/FXz/c/QXghTptj9R6/iZw0q3Z\n3H0zcH4Dr/kBcOWp5BCR0+vbY89h56FyZv5hPb26pDNuWN1+NJJMoikkdxK5TlJtZmWAEbnO3Tmm\nyUQkbqWkGN+/aSh7Dpcz/bnVZHdO56Izu4cdS0LS5MV2d+/k7inunubunYNlFRGRJNeuTSq/uL2A\nvt3bM+2JIt7fcyTsSBKSqKZIMbPrzez7weO6WIcSkcTQpX0acwtH0i4tlcmzl7LncHnYkSQE0UyR\nMhO4B3g3eNxjZg/EOpiIJIbcru2ZM3kkh8oqKZyzjKMnqsKOJC0smiOSa4Gr3H22u88GxgJ/F9tY\nIpJIBud04eEvXMCGPUf40lPLqayuCTuStKBoZ//NrPW8SyyCiEhiu3xAFg/cMIS/bNzPfQvWaIxJ\nEomm19YDwAoz+z8iPbYuQzPuikg9bh7Zh5LSMmYt2UjvzAy+cdVJvfulFWqykLj7M2b2Z2Bk0PRt\nd9fNCUSkXl//TH92BsUkJzODm0f2aXonSWjRXGy/ATju7ovcfRFQbmaaul1E6mVm/OeEIVzavwf3\nLlzDK+9r9u3WLpprJN91949m+3X3UuC7sYskIokuLTWFh28bwYDsTnz5qeWsLTldE4ZLPIqmkNS3\nje71LiKN6pQeGWPSJSONwrnL2HHweNiRJEaiKSRFZvbfZnZW8PghsDzWwUQk8WV3TmfulFGUV1Yz\nec4yDh2vDDuSxEA0heRuoAL43+BRDnwllqFEpPUYkN2JR28vYNsHx5n2ZBEnqnRTrNYmmrm2jrn7\nDHcvAC4EHnB33bhZRKJ28Vndeeimoby95QDfem41NbopVqsSTa+tX5pZ5+AGU2uAd81seuyjiUhr\nMm5YDjOuOYffrtrJf724Puw4chpFc2prkLsfBsYDfwDygdtjmkpEWqU7LzuT2y/qx89f3cwTbxaH\nHUdOk2h6X6WZWRqRQvI/7l4Z3NFQROSUmBn3X38euw6Vc/+idWzdf4wX1+1hZ2kZvTMzmH71QMYP\n102yEk00RyQ/B4qBDsCrZtYPOBzLUCLSeqWmGD+5dTg5XTN4/PViSkrLcKCktIx7F6zh+RUlYUeU\nUxTNxfYfu3uOu18b3Gp3G/Dp2EcTkdYqo20qldUnn9goq6zmocUbQkgkzXHKAwuDYqIbDohIs+w5\nVP9NsHaWlrVwEmmuaKeRFxE5rXpnZpxSu8QvFRIRCcX0qweSkZb6sbaMtFSmXz0wpETySUV1asvM\nRgN5tbd39ydilElEksCHvbMeWryBktIyUs34j/HnqddWAmqykJjZk8BZwErgw7kNHFAhEZFmGT88\nh/HDc/jjut1Me3I5bescoUhiiOaIpIDIoESNHRGRmLjy3Gz6dW/P7Ne2cN3Q3mHHkVMUzTWStcAZ\nsQ4iIskrNcWYPDqPd7aVsmLbwbDjyCmKppD0IDK/1mIzW/ThI9bBRCS53FTQh07t2jD79eKwo8gp\niubU1v2xDiEi0rFdGz4/sg9z3ijm3mvOUTfgBBLNyPZX6ntE8+JmNtbMNpjZJjObUc/6rma20MxW\nm9lSMxtcZ32qma0ws9/VarvfzErMbGXwuDaaLCIS/yaNzsPdmfdmcdhR5BREM438RWa2zMyOmlmF\nmVWbWZNzbZlZKvBT4BpgEHCrmQ2qs9l9wEp3HwpMBGbVWX8P8F49L/9Ddx8WPF5oKouIJIY+3doz\ndvAZPPP2No5XaAKNRBHNNZL/AW4FNgIZwB1ECkRTRgGb3H2zu1cAzwLj6mwzCHgZwN3XA3lmlg1g\nZrnA3wGPRfFniUgrMWVMPofLq/j18h1hR5EoRTWy3d03AanuXu3uc4CxUeyWA2yvtbwjaKttFTAB\nwMxGAf2A3GDdj4B/Amrqee27g9Nhs82sa31/uJlNM7MiMyvat29fFHFFJB5c0K8r5+d2YfbrxbqT\nYoKIppAcN7O2wEoze9DMvhHlftGYCWSa2Uoi94ZfAVSb2XXAXndfXs8+PwPOBIYBu4Af1PfC7v6o\nuxe4e0FWVtZpiisisWZmTLkkny37j/Hn9/eGHUeiEE1BuD3Y7qvAMaAPcGMU+5UE234oN2j7iLsf\ndvdCdx9G5BpJFrAZGANcb2bFRE6JXWFmTwX77AmOjGqAXxA5hSYirci1Q3pxRud0Hn9tS9hRJArR\n9NraChjQy92/5+7/GJzqasoyoL+Z5QdHNLcAHxt/YmaZwTqIXHt5NSgu97p7rrvnBfu97O5fCPbp\nVeslbiAyYFJEWpG01BQmju7H65s+YP1u3Ucv3kXTa+tzRObZejFYHhbNgER3ryJyFLOYSM+r+e6+\nzszuMrO7gs3OBdaa2QYivbvuiSLzg2a2xsxWE7nB1jei2EdEEsw/jOpLeloKs3VUEvesqSm0zGw5\ncAXwZ3cfHrStcfchLZDvtCgoKPCioqKwY4jIKfrOwjU8t3wHb8y4gh4d24UdJ+mY2XJ3L2hqu2iu\nkVS6+6E6bepKISIxVzgmn4qqGp5+a1vYUaQR0RSSdWb2D0CqmfU3s58Ab8Q4l4gIZ/fsyKcGZvHk\nW1s5UVXd9A4SimgKyd3AecAJ4BngMPD1WIYSEfnQ1Evy2X/0BL9dtSvsKNKAaHptHXf377j7yGBc\nxnfcvbwlwomIXHJ2DwZkd+Tx17ag2yLFpwZn/22qZ5a7X3/644iIfJyZMWVMPjMWrOHNzR8w+qwe\nYUeSOhqbRv5iIlOcPAO8TWQsiYhIixs/PIcHF29g9mvFKiRxqLFTW2cQmZ13MJFZea8C9p/KNPIi\nIqdDeloqt13YlyXr91C8/1jYcaSOBgtJMA3Ji+4+CbgI2AT82cy+2mLpREQCt1/UjzYpxtw3isOO\nInU0erHdzNqZ2QTgKeArwI+BhS0RTESktp6d0/nc+b2ZX7SdQ2WVYceRWhosJGb2BPAmMAL4XtBr\n69/dvaShfUREYmnKmHyOV1Tzv8s0QDGeNHZE8gWgP5H5r94ws8PB40g0d0gUETndBud04cL8bsx7\nYytV1fXdqkjC0Ng1khR37xQ8Otd6dHL3zi0ZUkTkQ1MuyaektIzF6/aEHUUCp+sGVSIiLeIz52bT\nt1t7Hn9tc9hRJKBCIiIJJTXFKByTxzvbSlmx7WDYcQQVEhFJQDcV9KFTuzbMfr047CiCComIJKCO\n7drw+ZF9eGHNLnYdKgs7TtJTIRGRhDRpdB7uzrw3toYdJempkIhIQurTrT1Xn3cGzyzdxvGKqrDj\nJDUVEhFJWFMvyedQWSW/fkfjpMOkQiIiCeuCfl0ZmtuFOa9toaZG9yoJiwqJiCQsM2PqJfls3n+M\nV97fF3acpKVCIiIJ7dohvcju3I7HX9sSdpSkpUIiIgktLTWFiRfn8dqm/azfrWkAw6BCIiIJ77YL\n+5KelsKc14rDjpKUVEhEJOFltm/LjSNyWbiyhP1HT4QdJ+mokIhIq1A4Jp+Kqhqefkv3KmlpKiQi\n0iqc3bMjnxqYxZNvbeVEVXXYcZKKComItBpTxuSz/+gJfrtqV9hRkkpMC4mZjTWzDWa2ycxm1LO+\nq5ktNLPVZrbUzAbXWZ9qZivM7He12rqZ2UtmtjH42TWW70FEEsel/XswILsjs1/bgrsGKLaUmBUS\nM0sFfgpcAwwCbjWzQXU2uw9Y6e5DgYnArDrr7wHeq9M2A1ji7v2BJcGyiAhmxpQx+by76zBvbT4Q\ndpykEcsjklHAJnff7O4VwLPAuDrbDAJeBnD39UCemWUDmFku8HfAY3X2GQfMC57PA8bHJr6IJKLx\nw3Po1qGtBii2oFgWkhxge63lHUFbbauACQBmNgroB+QG634E/BNQU2efbHf/8ATobiC7vj/czKaZ\nWZGZFe3bp6kTRJJFeloqt13YlyXr91C8/1jYcZJC2BfbZwKZZrYSuBtYAVSb2XXAXndf3tjOHjkJ\nWu+JUHd/1N0L3L0gKyvrdOcWkTh2+0X9aJNizH2jOOwoSSGWhaQE6FNrOTdo+4i7H3b3QncfRuQa\nSRawGRgDXG9mxUROiV1hZk8Fu+0xs14Awc+9MXwPIpKAenZO53NDezO/aDuHyirDjtPqxbKQLAP6\nm1m+mbUFbgEW1d7AzDKDdQB3AK8GxeVed89197xgv5fd/QvBdouAScHzScBvYvgeRCRBTbkkn+MV\n1cxftr3pjaVZYlZI3L0K+CqwmEjPq/nuvs7M7jKzu4LNzgXWmtkGIr277onipWcCV5nZRuAzwbKI\nyMcMzunCqPxuzH2jmKrqupda5XSyZOhrXVBQ4EVFRWHHEJEWtnjdbu58cjkP3zaCa4f0CjtOwjGz\n5e5e0NR/GnbWAAAK1ElEQVR2YV9sFxGJmc+cm03fbu3VFTjGVEhEpNVKTTEmj85j+daDrNxeGnac\nVkuFRERatZtH9qFTuzbM1lFJzKiQiEir1rFdG24e2YcX1uxi16GysOO0SiokItLqTR6dR407T7y5\nNeworZIKiYi0en26tefq887gl29v43hFVdhxWh0VEhFJClMuyedQWSW/fqek6Y3llKiQiEhSKOjX\nlaG5XZjz+hZqalr/+LmWpEIiIknBzJh6ST6b9x3jlfc1I/jppEIiIknjmsG9yO7cjtmvqyvw6aRC\nIiJJo22bFCZenMdfNu5nw+4jYcdpNVRIRCSp/MOovqSnpWiA4mmkQiIiSaVrh7ZMGJHLwpUlfHD0\nRNhxWgUVEhFJOlPG5FFRVcPTb28LO0qroEIiIknn7J6duHxAFk++tZUTVdVhx0l4KiQikpSmXpLP\nviMn+N2qXWFHSXgqJCKSlC7t34P+PTvy+GtbSIYb/MWSComIJCUzY8ol+by76zBvbzkQdpyEpkIi\nIknrhuE5dG2fpjsoNpMKiYgkrfS0VG67sB9/em8PxfuPhR0nYamQiEhSm3hxP9qkGHPfKA47SsJS\nIRGRpNazczqfG9qb54q2c7i8Muw4CUmFRESS3pRL8jlWUc38ZdvDjpKQVEhEJOkNzunCqPxuzHm9\nmKrqmrDjJBwVEhERYMqYfEpKy/jju3vCjpJwVEhERICrBmXTt1t7zQr8CaiQiIgAqSnG5NF5FG09\nyKrtpWHHSSgqJCIigZsKcunYro3uoHiKYlpIzGysmW0ws01mNqOe9V3NbKGZrTazpWY2OGhPD5ZX\nmdl7Zjaz1j73m1mJma0MHtfG8j2ISPLolJ7G50f24ferd7H7UHnYcRJGzAqJmaUCPwWuAQYBt5rZ\noDqb3QesdPehwERgVtB+ArjC3c8HhgKfNrNLa+33Q3cfFjxeiNV7EJHkM3l0HjXuzHuzOOwoCSOW\nRySjgE3uvtndK4BngXF1thkEvAzg7uuBPDPL9oijwTZpQCpwMIZZRUQA6NOtPZ8ddAa/fHsbZRW6\nV0k0YllIcoDao3t2BG21rQImAJjZKKAfkBssp5rZSmAv8Gd3X1trv7uD02GzzaxrrN6AiCSnqZfm\nc6iskl+/syPsKAkh7IvtM4HMoGDcDawAqgHcvdrdhxEpLJea2aeDfX4GnAkMA3YBP6jvhc1smpkV\nmVnRvn37Yvw2RKQ1KejXlSE5XZjz+hZqanSvkqbEspCUAH1qLecGbR9x98PuXhgUjIlAFrC5zjal\nwO+BgmB5T1BkaoBfEDmFdhJ3f9TdC9y9ICsr63S9JxFJAmbG1Evy+eu+Y7yyUb+INiWWhWQZ0N/M\n8s2sLXALsKj2BmaWGawDuAN41d0Pm1mWmWUG22QAVwErg+VetV7iBqD2KS8RkdPi2iG9yO7cTgMU\no9AmVi/s7lVm9lVgMZGL5bPdfZ2Z3RWsfwQ4F5hnZg6sA6YGu/cK2lOIFLun3P2lYN2DZjYMcKAY\nuDNW70FEklfbNilMvDiPhxZv4P09RxiQ3SnsSHHLkuFexQUFBV5UVBR2DBFJMAePVXDxzCWMH5bD\nzBuHhh2nxZnZcncvaGq7sC+2i4jEra4d2jJhRC4LVpTwwdETYceJWyokIiKNmDImj4qqGn759raw\no8QtFRIRkUac3bMTlw/I4om3tnKiSgMU66NCIiLShCmX5LPvyAl+v3pX2FHiUsx6bYmItBaX9e9B\ndqd2fPvXq/nm/FX0zsxg+tUDGT+87mQd8eP5FSU8tHgDO0vLYp5XhUREpAm/WbmTA8crqKyO9HIt\nKS3j3gVrAOKymDy/ooR7F6yhrDJyKi7WedX9V0SkCWNmvkxJadlJ7W1SjPweHUJI1Lgt+49RVc/U\nLjmZGbw+44qoXyfa7r86IhERacLOeooIQFWN0z+7YwunadrGvUfrbW/ofTSXComISBN6Z2bUe0SS\nk5nBw7ddEEKixjV0BNU7MyMmf556bYmINGH61QPJSEv9WFtGWirTrx4YUqLGtXReHZGIiDThwwvU\nLdULqrlaOq8utouISL0015aIiLQIFRIREWkWFRIREWkWFRIREWkWFRIREWmWpOi1ZWb7gK1h56ij\nB7A/7BBRSqSskFh5EykrJFbeRMoK8Zm3n7tnNbVRUhSSeGRmRdF0q4sHiZQVEitvImWFxMqbSFkh\n8fLWplNbIiLSLCokIiLSLCok4Xk07ACnIJGyQmLlTaSskFh5EykrJF7ej+gaiYiINIuOSEREpFlU\nSFqYmWWa2a/MbL2ZvWdmF4edqTFmdq+ZvWtma83sGTNLDztTbWY228z2mtnaWm3dzOwlM9sY/Owa\nZsYPNZD1oeCzsNrMFppZZpgZa6svb6113zQzN7MeYWSrq6GsZnZ38Pe7zsweDCtfXQ18FkaZ2TIz\nW2lmRWY2KsyMp0KFpOXNAl5093OA84H3Qs7TIDPLA6YBF7j7YCAVuCXMTPWYC4yt0zYDWOLu/YEl\nwXI8mMvJWV8CBrv7UOB94N6WDtWIuZycFzPrA3wW2NbSgRoxlzpZzezTwDjgfHc/D/h+CLkaMpeT\n/24fBP7V3YcB/xosJwQVkhZkZl2Ay4DHAdy9wt1Lw03VqMNAJZBhZm2A9sDOcCN9nLu/Chyo0zwO\nmBc8nweMb9FQDagvq7v/0d2rgsW3gNwWD9aABv5uAX4I/BMQNxdYG8j6JWCmu58Ittnb4sEa0EDe\n3UDn4HkX4uz/WmNUSFpWPrAPmGNmK8zsMTPrEHaohrj7ASK/xW0DdgGH3P2P4aaKSra77wqe7way\nwwxzCqYAfwg7RGPMbBxQ4u6rws4ShQHApWb2tpm9YmYjww7UhG8DPzCz7UT+38XT0WmjVEhaVhtg\nBPAzdx8OHCN+TrucxMzOAr5BpAD2BjqY2RfCTXVqPNItMW5+c26ImX0HqAKeDjtLQ8ysPXAfkdMu\niaAN0A24CJgOzDczCzdSox4H7nH3PkT+3z0ecp6oqZC0rB3ADnd/O1j+FZHCEq8KgDfcfZ+7VwIL\ngNEhZ4rGHjPrBRD8jJtTGvUxs8nAdcBtHt/98c8i8kvFKjMrJnIa7h0zOyPUVA3bASzwiKVADZH5\nrOLVhUT+jwE8B+hiu5zM3XcD281sYNB0JfBuiJGasgG4yMzaB7/JXUkcdw6oZREwKXg+CfhNiFka\nZWZjiVxvuN7dj4edpzHuvsbde7p7nrvnEfmiHhF8ruPR88CnAcxsANCW+JsUsbZNwOXB8yuAjSFm\nOTXurkcLPoBhQBGwmsgHvWvYmZrI+20ixW4t8CTQLuxMdfI9Q+T6TSWRL7apQHcivbU2An8CuoWd\ns5Gsm4DtwMrg8UjYORvLW2d9MdAj7JyN/N22BZ4KPrvvAFeEnbOJvCOBpcAq4G0ivSVDzxrNQyPb\nRUSkWXRqS0REmkWFREREmkWFREREmkWFREREmkWFREREmkWFRCQEZpZX36y6IolIhURERJpFhUQk\nZGZ2ZjCJZ7xPKihSrzZhBxBJZsF0Oc8Ckz0xZtQVOYkKiUh4sojMAzbB3eN5zjWRRunUlkh4DhG5\n18slYQcRaQ4dkYiEpwK4AVhsZkfd/ZdhBxL5JFRIRELk7sfM7DrgpaCYLAo7k8ip0uy/IiLSLLpG\nIiIizaJCIiIizaJCIiIizaJCIiIizaJCIiIizaJCIiIizaJCIiIizaJCIiIizfL/AS4RMS/I+z9w\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4b5417fa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the mean score vs k\n",
    "plt.plot(np.arange(5,20,2), meanScores, 'o-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Mean score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like k=7 is a good choice for this data set. You can search an optimal parameter this way.\n",
    "\n",
    "Or, there is a tool called **`GridSearchCV`** under **`sklearn.model_selection`**. It performs cross validation for different values of parameters, and pick the best one for you. To use `GridSearchCV`, first you have to define combinations of parameter values to be examined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using a grid search\n",
    "param = {'n_neighbors':list(range(5,20,2)),\n",
    "         'weights':['uniform', 'distance']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, possible values of parameters are stored in a *dictionary* called **`param`**. Notice that the parameter k's actual name is **`n_neighbors`**. We also need to define any other parameters that are not the default values in a classifier. In this case, we will examine **`weights`** to be either **`'uniform'`** or **`'distance'`**, just for fun. The next step is to define the classifier object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kNN = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we don't have to worry about the parameters set in `param`. Now we have a classifier object and the parameter dictionary, we define the grid search object **`GridSearchCV`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [5, 7, 9, 11, 13, 15, 17, 19], 'weights': ['uniform', 'distance']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_kNN = GridSearchCV(kNN, param, cv=5)\n",
    "grid_kNN.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the grid search object `GridSearchCV`, we need to provide the classifier object and the parameter library. You can specify the number of folds to be used in cross validation as parameter **`cv`**. Here, we try 5-fold cross validation as before. Once the grid search object `GridSearchCV` is defined, then we use the **`fit`** to learn from the features and targets. Here, we provide the entire data set. Now let's see what the winning combination of the parameters was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 7, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "print(grid_kNN.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, again, k=7 seems to be the winner (and `uniform` weighting). And here is the mean accuracy score resulting from that combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n"
     ]
    }
   ],
   "source": [
    "print(grid_kNN.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can check the winning combination on another testing data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24  0  0]\n",
      " [ 0 18  1]\n",
      " [ 0  3 14]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        24\n",
      " versicolor       0.86      0.95      0.90        19\n",
      "  virginica       0.93      0.82      0.87        17\n",
      "\n",
      "avg / total       0.94      0.93      0.93        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the winning combination\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,\n",
    "                                                    random_state=2018)\n",
    "kNN = KNeighborsClassifier(7, weights='uniform')\n",
    "kNN.fit(X_train,y_train)\n",
    "y_pred = kNN.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test, y_pred,\n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "1. **Iris data, parameter search for SVM**. Say, you want to use a support vector machine (SVM) classifier instead to a kNN classifier on the iris data. Determine the best combination of parameters to use with a grid search with 5-fold cross validation. These are the possible values of the parameters:\n",
    "\n",
    "  * **`C`**: `[10, 1.0, 0.1]`\n",
    "  * **`kernel`**: `['linear', 'rbf', 'poly']`\n",
    "\n",
    "  Print out the best parameter combination, and the mean score associated with that combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: seed data\n",
    "\n",
    "As you recall that the seed data features need to be standardized before cross validation. Thus, we had to create a pipeline of standardization and a classifier. If we want to perform a grid search on classifier parameters, we need to do the same. However, since the classifier has to be run under different combinations of parameters, we have to use **`Pipeline`** function under **`sklearn.pipeline`** to construct the pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<SeedGridSearch.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# loading the data \n",
    "seedData = pd.read_csv('seeds_dataset.txt', sep='\\t', header=None)\n",
    "seedFeatures = np.array(seedData.iloc[:,:7])\n",
    "seedTargets = np.array(seedData.iloc[:,7]) - 1 # starting from zero\n",
    "targetNames = ['Kama','Rosa','Canadian']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline created by the **`Pipeline`** function is a list of tuples, with each tuple containing a name you assign to a transformation object, and the object.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipeline of transformations\n",
    "svm = Pipeline([\n",
    "    ('normalize',StandardScaler()),\n",
    "    ('classify',SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And parameters need to be specified as to which steps of the pipeline they are going to be used. Do do so, the name of the parameter has to be prefixed by the step name in the pipeline (e.g., `'classify'`) and two underscores (`__`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {'classify__C': [10,1,0.1],\n",
    "         'classify__kernel': ['rbf','poly','linear']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you pass on the parameters under the **`param_grid`** parameter in the `GridSearchCV` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('normalize', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classify', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'classify__kernel': ['rbf', 'poly', 'linear'], 'classify__C': [10, 1, 0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search\n",
    "grid_svm = GridSearchCV(svm, param_grid=param, cv=10)\n",
    "grid_svm.fit(seedFeatures,seedTargets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the winning combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classify__kernel': 'linear', 'classify__C': 10}\n",
      "0.947619047619\n"
     ]
    }
   ],
   "source": [
    "print(grid_svm.best_params_)\n",
    "print(grid_svm.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the winning combination in another testing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21  1  2]\n",
      " [ 2 26  0]\n",
      " [ 0  0 18]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Kama       0.91      0.88      0.89        24\n",
      "       Rosa       0.96      0.93      0.95        28\n",
      "   Canadian       0.90      1.00      0.95        18\n",
      "\n",
      "avg / total       0.93      0.93      0.93        70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the winning combination\n",
    "X_train, X_test, y_train, y_test = train_test_split(seedFeatures,\n",
    "                                                    seedTargets, \n",
    "                                                    test_size=70, \n",
    "                                                    random_state=0)\n",
    "normTrain = StandardScaler().fit(X_train)\n",
    "X_train_norm = normTrain.transform(X_train)\n",
    "X_test_norm = normTrain.transform(X_test)\n",
    "sv = SVC(kernel='linear',C=10)\n",
    "sv.fit(X_train_norm,y_train)\n",
    "y_pred = sv.predict(X_test_norm)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test, y_pred,\n",
    "                            target_names=targetNames))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
