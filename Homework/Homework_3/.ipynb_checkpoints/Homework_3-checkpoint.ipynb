{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### QUESTION 1 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Load the data\n",
    "\n",
    "df = pd.read_csv('tae.csv',header=None)\n",
    "df = df.rename(index=int, columns={0: \"english\", 1: \"instructor\", 2: \"course\", 3:\"semester\", 4:\"size\", 5:'eval'})\n",
    "featureNames = ['english','instructor','course','semester','size']\n",
    "targetNames = ['Low','Medium','High']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encoding categorical variables (all but size)\n",
    "\n",
    "# the target\n",
    "\n",
    "evalLE = LabelEncoder()\n",
    "y = evalLE.fit_transform(df['eval'])\n",
    "y_class = evalLE.classes_\n",
    "\n",
    "# the features\n",
    "\n",
    "englishLE = LabelEncoder()\n",
    "englishx = englishLE.fit_transform(df['english'])\n",
    "englishx_class = englishLE.classes_\n",
    "\n",
    "instructorLE = LabelEncoder()\n",
    "instructorx = instructorLE.fit_transform(df['instructor'])\n",
    "instructorx_class = instructorLE.classes_\n",
    "\n",
    "courseLE = LabelEncoder()\n",
    "coursex = courseLE.fit_transform(df['course'])\n",
    "coursex_class = courseLE.classes_\n",
    "\n",
    "semesterLE = LabelEncoder()\n",
    "semesterx = semesterLE.fit_transform(df['semester'])\n",
    "semesterx_class = semesterLE.classes_\n",
    "\n",
    "# recreate features\n",
    "\n",
    "X = np.vstack([englishx,instructorx,coursex,semesterx,df['size']]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Parameters: {'classification__criterion': 'gini', 'classification__max_depth': 13, 'classification__min_samples_leaf': 1, 'classification__n_estimators': 10}\n",
      "Model Accuracy: 0.7218543046357616\n"
     ]
    }
   ],
   "source": [
    "### Classification Model:Random Forest\n",
    "\n",
    "# build base model pipeline\n",
    "rf = Pipeline([\n",
    "    ('normalization',StandardScaler()),\n",
    "    ('classification',RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# list hyperparameters of model\n",
    "param_rf = {'classification__criterion': ['entropy','gini'], 'classification__n_estimators': [1,5,7,10], \n",
    "            'classification__max_depth':[4,5,6,7,8,9,10,11,12,13], 'classification__min_samples_leaf': [1,2,3,4,5,6,7,8]}\n",
    "            \n",
    "# using a grid search to build hyper parameters to test\n",
    "grid_rf = GridSearchCV(rf, param_rf, cv=5)\n",
    "grid_rf.fit(X,y)\n",
    "\n",
    "# Optimal set of hyperparameters and its corresponding accuracy score\n",
    "print (\"Optimal Parameters of RF: %s\" % grid_rf.best_params_)\n",
    "print (\"Model Accuracy of RF: %s\" % grid_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### QUESTION 2 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Parameters of RF with Variable 'expense': {'classification__criterion': 'gini', 'classification__max_depth': 4, 'classification__min_samples_leaf': 8, 'classification__n_estimators': 1}\n",
      "Model Accuracy of RF with Variable 'expense': 0.8888888888888888 \n",
      "\n",
      "Optimal Parameters of RF without Variable 'expense': {'classification__criterion': 'entropy', 'classification__max_depth': 12, 'classification__min_samples_leaf': 1, 'classification__n_estimators': 7}\n",
      "Model Accuracy of RF without Variable 'expense': 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "### Load the data\n",
    "\n",
    "# read file\n",
    "with open('university_data.txt', 'r') as f:\n",
    "    raw_data = f.read().lower()\n",
    "\n",
    "# split observations\n",
    "split_data = raw_data.split(\"(def-\")\n",
    "\n",
    "# remove duplicates and nulls\n",
    "filter_data = []\n",
    "for data in split_data:\n",
    "    if \"duplicate\" in data:\n",
    "        pass\n",
    "    elif len(data) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        filter_data.append(data)\n",
    "\n",
    "# handle multiple academic-emphasis features\n",
    "raw_feature_data = []\n",
    "for data in filter_data:\n",
    "    temp=[]\n",
    "    temp = data.split(\"(academic-emphasis\")\n",
    "    raw_feature_data.append(temp[0])\n",
    "\n",
    "# split features and assign to feature key\n",
    "feature_data = []\n",
    "for data in raw_feature_data:\n",
    "    temp = data.split(\"(\")\n",
    "    feature_data.append(temp) \n",
    "features = [\"instance\", \"state \",\"control\",\"location\",\"no-of-students thous:\",\"male:female ratio:\",\n",
    "            \"student:faculty ratio:\",\"sat verbal\", \"sat math\",\"expenses thous$:\",\"percent-financial-aid\",\n",
    "            \"no-applicants thous:\",\"percent-admittance\",\"percent-enrolled\",\"academics scale:\",\"social scale:\",\n",
    "            \"quality-of-life scale:\"]\n",
    "feature_split_data = []\n",
    "for x in feature_data:\n",
    "    temp = {}\n",
    "    for y in x:\n",
    "        for feature in features:\n",
    "            if feature in y:\n",
    "                value = y.split(feature)\n",
    "                temp[feature] =value[1]\n",
    "    feature_split_data.append(temp)\n",
    "                \n",
    "# preprocess data to obtain usable format for models\n",
    "preprocessed_data =[]\n",
    "for x in feature_split_data:\n",
    "    temp ={}\n",
    "    for key,value in x.items():\n",
    "        value = value.replace(\")\",\"\");\n",
    "        value = value.replace(\" \",\"\");\n",
    "        value = value.replace(\"%\",\"\")\n",
    "        value = value.replace(\"private:roman-catholic\",\"private\")\n",
    "        value = value.replace(\"city\",\"state\")\n",
    "        value = value.replace(\"\\n\",\"\")\n",
    "        value = value.replace(\"act-21\",\"0\")\n",
    "        value = value.replace(\"act-15\",\"0\")\n",
    "        value = value.replace(\"n/a\",\"0\")\n",
    "        value = value.replace(\"?\",\"0\")\n",
    "        value = value.replace(\"na\",\"0\")\n",
    "        if \"+\" in value:\n",
    "            value = int(value.replace(\"+\",\"\"))\n",
    "        elif \"1-5\" in value:\n",
    "            value1 = value.replace(\"1-5\",\"\")\n",
    "            value = int(value1)\n",
    "        elif \"-\" in value and len(value)<7:\n",
    "            data1 = value.split(\"-\")\n",
    "            if data1[1] == '':\n",
    "                data1[1] = \"0\"\n",
    "            value = (int(data1[0]) + int(data1[1]))/2\n",
    "        elif \":\" in value and len(value)<9:\n",
    "            data2 = value.split(\":\")\n",
    "            if data2[1] != \"0\":\n",
    "                value = int(data2[0])/int(data2[1])\n",
    "            else:\n",
    "                value = int(data2[0])\n",
    "        try:\n",
    "            value =float(value)\n",
    "        except ValueError:\n",
    "            value = value        \n",
    "        temp[key] = value\n",
    "    preprocessed_data.append(temp)\n",
    "    \n",
    "# convert standarized data to dataframe\n",
    "data_for_dataframe=[]\n",
    "for x in preprocessed_data:\n",
    "    temp = x\n",
    "    for feature in features:\n",
    "        if feature not in x:\n",
    "            temp[feature] = None\n",
    "    data_for_dataframe.append(temp)\n",
    "            \n",
    "df =pd.DataFrame(data_for_dataframe)\n",
    "\n",
    "# impute NAs with mean\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "df = df.replace(to_replace='None', value=np.nan).dropna()\n",
    "\n",
    "# change target values from state to public (since we are categorizing public vs private)\n",
    "df['control'] = df['control'].replace(to_replace='state', value='public')\n",
    "\n",
    "## Encoding categorical variables\n",
    "\n",
    "# the target\n",
    "\n",
    "controlLE = LabelEncoder()\n",
    "y = controlLE.fit_transform(df['control'])\n",
    "y_class = controlLE.classes_\n",
    "\n",
    "# the features\n",
    "\n",
    "locationLE = LabelEncoder()\n",
    "locationx = locationLE.fit_transform(df['location'])\n",
    "locationx_class = locationLE.classes_\n",
    "\n",
    "academicLE = LabelEncoder()\n",
    "academicx = academicLE.fit_transform(df['academics scale:'])\n",
    "academicx_class = academicLE.classes_\n",
    "\n",
    "socialLE = LabelEncoder()\n",
    "socialx = socialLE.fit_transform(df['social scale:'])\n",
    "socialx_class = socialLE.classes_\n",
    "\n",
    "qualityLE = LabelEncoder()\n",
    "qualityx = qualityLE.fit_transform(df['quality-of-life scale:'])\n",
    "qualityx_class = qualityLE.classes_\n",
    "\n",
    "# recreate feature variables\n",
    "X = np.vstack([locationx,academicx,socialx,qualityx,df['male:female ratio:'],df['no-of-students thous:']\n",
    "               ,df['sat verbal'],df['sat math'],df['expenses thous$:'],df['percent-financial-aid']\n",
    "               ,df['no-applicants thous:'],df['percent-admittance'],df['percent-enrolled']\n",
    "               ,df['percent-enrolled']]).T\n",
    "\n",
    "\n",
    "### Feature Selection and Classification Model:Random Forest w/variable 'Expenses'\n",
    "\n",
    "# build base model pipline\n",
    "rf = Pipeline([\n",
    "    ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l2\"))),\n",
    "    ('normalization',StandardScaler()),\n",
    "    ('classification',RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# list hyperparameters of model\n",
    "param_rf = {'classification__criterion': ['entropy','gini'], 'classification__n_estimators': [1,5,7,10], \n",
    "            'classification__max_depth':[4,5,6,7,8,9,10,11,12,13], 'classification__min_samples_leaf': [1,2,3,4,5,6,7,8]}\n",
    "            \n",
    "# using a grid search to build hyper parameters to test\n",
    "grid_rf = GridSearchCV(rf, param_rf, cv=5)\n",
    "grid_rf.fit(X,y)\n",
    "\n",
    "# Optimal set of hyperparameters and its corresponding accuracy score\n",
    "print (\"Optimal Parameters of RF with Variable 'expense': %s\" % grid_rf.best_params_)\n",
    "print (\"Model Accuracy of RF with Variable 'expense': %s \\n\" % grid_rf.best_score_)\n",
    "\n",
    "### Feature Selection and Classification Model:Random Forest w/o variable 'Expenses'\n",
    "\n",
    "# recreate feature variables without the variable 'expense'\n",
    "X = np.vstack([locationx,academicx,socialx,qualityx,df['male:female ratio:'],df['no-of-students thous:']\n",
    "               ,df['sat verbal'],df['sat math'],df['percent-financial-aid']\n",
    "               ,df['no-applicants thous:'],df['percent-admittance'],df['percent-enrolled']\n",
    "               ,df['percent-enrolled']]).T\n",
    "\n",
    "# build base model pipline\n",
    "rf = Pipeline([\n",
    "    ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l2\"))),\n",
    "    ('normalization',StandardScaler()),\n",
    "    ('classification',RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# list hyperparameters of model\n",
    "param_rf = {'classification__criterion': ['entropy','gini'], 'classification__n_estimators': [1,5,7,10], \n",
    "            'classification__max_depth':[4,5,6,7,8,9,10,11,12,13], 'classification__min_samples_leaf': [1,2,3,4,5,6,7,8]}\n",
    "            \n",
    "# using a grid search to build hyper parameters to test\n",
    "grid_rf = GridSearchCV(rf, param_rf, cv=5)\n",
    "grid_rf.fit(X,y)\n",
    "\n",
    "# Optimal set of hyperparameters and its corresponding accuracy score\n",
    "print (\"Optimal Parameters of RF without Variable 'expense': %s\" % grid_rf.best_params_)\n",
    "print (\"Model Accuracy of RF without Variable 'expense': %s\" % grid_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Parameters of RF with Variable 'expense': {'classification__criterion': 'entropy', 'classification__max_depth': 4, 'classification__min_samples_leaf': 3, 'classification__n_estimators': 5}\n",
      "Model Accuracy of RF with Variable 'expense': 0.9166666666666666 \n",
      "\n",
      "Optimal Parameters of RF without Variable 'expense': {'classification__criterion': 'entropy', 'classification__max_depth': 11, 'classification__min_samples_leaf': 2, 'classification__n_estimators': 10}\n",
      "Model Accuracy of RF without Variable 'expense': 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "## Author : Sanchit Singhal\n",
    "## Date : 03/25/2019\n",
    "\n",
    "## import required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "### Load the data\n",
    "\n",
    "# read file\n",
    "with open('university_data.txt', 'r') as f:\n",
    "    raw_data = f.read().lower()\n",
    "\n",
    "# split observations\n",
    "split_data = raw_data.split(\"(def-\")\n",
    "\n",
    "# remove duplicates and nulls\n",
    "filter_data = []\n",
    "for data in split_data:\n",
    "    if \"duplicate\" in data:\n",
    "        pass\n",
    "    elif len(data) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        filter_data.append(data)\n",
    "\n",
    "# handle multiple academic-emphasis features\n",
    "raw_feature_data = []\n",
    "for data in filter_data:\n",
    "    temp=[]\n",
    "    temp = data.split(\"(academic-emphasis\")\n",
    "    raw_feature_data.append(temp[0])\n",
    "\n",
    "# split features and assign to feature key\n",
    "feature_data = []\n",
    "for data in raw_feature_data:\n",
    "    temp = data.split(\"(\")\n",
    "    feature_data.append(temp)\n",
    "features = [\"instance\", \"state \",\"control\",\"location\",\"no-of-students thous:\",\"male:female ratio:\",\n",
    "            \"student:faculty ratio:\",\"sat verbal\", \"sat math\",\"expenses thous$:\",\"percent-financial-aid\",\n",
    "            \"no-applicants thous:\",\"percent-admittance\",\"percent-enrolled\",\"academics scale:\",\"social scale:\",\n",
    "            \"quality-of-life scale:\"]\n",
    "feature_split_data = []\n",
    "for x in feature_data:\n",
    "    temp = {}\n",
    "    for y in x:\n",
    "        for feature in features:\n",
    "            if feature in y:\n",
    "                value = y.split(feature)\n",
    "                temp[feature] =value[1]\n",
    "    feature_split_data.append(temp)\n",
    "\n",
    "# preprocess data to obtain usable format for models\n",
    "preprocessed_data =[]\n",
    "for x in feature_split_data:\n",
    "    temp ={}\n",
    "    for key,value in x.items():\n",
    "        value = value.replace(\")\",\"\");\n",
    "        value = value.replace(\" \",\"\");\n",
    "        value = value.replace(\"%\",\"\")\n",
    "        value = value.replace(\"private:roman-catholic\",\"private\")\n",
    "        value = value.replace(\"city\",\"state\")\n",
    "        value = value.replace(\"\\n\",\"\")\n",
    "        value = value.replace(\"act-21\",\"0\")\n",
    "        value = value.replace(\"act-15\",\"0\")\n",
    "        value = value.replace(\"n/a\",\"0\")\n",
    "        value = value.replace(\"?\",\"0\")\n",
    "        value = value.replace(\"na\",\"0\")\n",
    "        if \"+\" in value:\n",
    "            value = int(value.replace(\"+\",\"\"))\n",
    "        elif \"1-5\" in value:\n",
    "            value1 = value.replace(\"1-5\",\"\")\n",
    "            value = int(value1)\n",
    "        elif \"-\" in value and len(value)<7:\n",
    "            data1 = value.split(\"-\")\n",
    "            if data1[1] == '':\n",
    "                data1[1] = \"0\"\n",
    "            value = (int(data1[0]) + int(data1[1]))/2\n",
    "        elif \":\" in value and len(value)<9:\n",
    "            data2 = value.split(\":\")\n",
    "            if data2[1] != \"0\":\n",
    "                value = int(data2[0])/int(data2[1])\n",
    "            else:\n",
    "                value = int(data2[0])\n",
    "        try:\n",
    "            value =float(value)\n",
    "        except ValueError:\n",
    "            value = value\n",
    "        temp[key] = value\n",
    "    preprocessed_data.append(temp)\n",
    "\n",
    "# convert standarized data to dataframe\n",
    "data_for_dataframe=[]\n",
    "for x in preprocessed_data:\n",
    "    temp = x\n",
    "    for feature in features:\n",
    "        if feature not in x:\n",
    "            temp[feature] = None\n",
    "    data_for_dataframe.append(temp)\n",
    "\n",
    "df =pd.DataFrame(data_for_dataframe)\n",
    "\n",
    "# impute NAs with mean\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "df = df.replace(to_replace='None', value=np.nan).dropna()\n",
    "\n",
    "# change target values from state to public (since we are categorizing public vs private)\n",
    "df['control'] = df['control'].replace(to_replace='state', value='public')\n",
    "\n",
    "## Encoding categorical variables\n",
    "\n",
    "# the target\n",
    "\n",
    "controlLE = LabelEncoder()\n",
    "y = controlLE.fit_transform(df['control'])\n",
    "y_class = controlLE.classes_\n",
    "\n",
    "# the features\n",
    "\n",
    "locationLE = LabelEncoder()\n",
    "locationx = locationLE.fit_transform(df['location'])\n",
    "locationx_class = locationLE.classes_\n",
    "\n",
    "academicLE = LabelEncoder()\n",
    "academicx = academicLE.fit_transform(df['academics scale:'])\n",
    "academicx_class = academicLE.classes_\n",
    "\n",
    "socialLE = LabelEncoder()\n",
    "socialx = socialLE.fit_transform(df['social scale:'])\n",
    "socialx_class = socialLE.classes_\n",
    "\n",
    "qualityLE = LabelEncoder()\n",
    "qualityx = qualityLE.fit_transform(df['quality-of-life scale:'])\n",
    "qualityx_class = qualityLE.classes_\n",
    "\n",
    "# recreate feature variables (not using university name, state, academic emphasis)\n",
    "X = np.vstack([locationx,academicx,socialx,qualityx,df['male:female ratio:'],df['no-of-students thous:']\n",
    "               ,df['sat verbal'],df['sat math'],df['expenses thous$:'],df['percent-financial-aid']\n",
    "               ,df['no-applicants thous:'],df['percent-admittance'],df['percent-enrolled']\n",
    "               ,df['student:faculty ratio:']]).T\n",
    "\n",
    "### Feature Selection and Classification Model:Random Forest w/variable 'Expenses'\n",
    "\n",
    "# build base model pipline\n",
    "rf = Pipeline([\n",
    "    ('normalization',StandardScaler()),\n",
    "    ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l2\"))),\n",
    "    ('classification',RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# list hyperparameters of model\n",
    "param_rf = {'classification__criterion': ['entropy','gini'], 'classification__n_estimators': [1,5,7,10],\n",
    "            'classification__max_depth':[4,5,6,7,8,9,10,11,12,13], 'classification__min_samples_leaf': [1,2,3,4,5,6,7,8]}\n",
    "\n",
    "# using a grid search to build hyper parameters to test\n",
    "grid_rf = GridSearchCV(rf, param_rf, cv=5)\n",
    "grid_rf.fit(X,y)\n",
    "\n",
    "# Optimal set of hyperparameters and its corresponding accuracy score\n",
    "print (\"Optimal Parameters of RF with Variable 'expense': %s\" % grid_rf.best_params_)\n",
    "print (\"Model Accuracy of RF with Variable 'expense': %s \\n\" % grid_rf.best_score_)\n",
    "\n",
    "### Feature Selection and Classification Model:Random Forest w/o variable 'Expenses'\n",
    "\n",
    "# recreate feature variables without the variable 'expense' (not using university name, state, academic emphasis)\n",
    "X = np.vstack([locationx,academicx,socialx,qualityx,df['male:female ratio:'],df['no-of-students thous:']\n",
    "               ,df['sat verbal'],df['sat math'],df['percent-financial-aid']\n",
    "               ,df['no-applicants thous:'],df['percent-admittance'],df['percent-enrolled']\n",
    "               ,df['student:faculty ratio:']]).T\n",
    "\n",
    "# build base model pipline\n",
    "rf = Pipeline([\n",
    "    ('normalization',StandardScaler()),\n",
    "    ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l2\"))),\n",
    "    ('classification',RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# list hyperparameters of model\n",
    "param_rf = {'classification__criterion': ['entropy','gini'], 'classification__n_estimators': [1,5,7,10],\n",
    "            'classification__max_depth':[4,5,6,7,8,9,10,11,12,13], 'classification__min_samples_leaf': [1,2,3,4,5,6,7,8]}\n",
    "\n",
    "# using a grid search to build hyper parameters to test\n",
    "grid_rf = GridSearchCV(rf, param_rf, cv=5)\n",
    "grid_rf.fit(X,y)\n",
    "\n",
    "# Optimal set of hyperparameters and its corresponding accuracy score\n",
    "print (\"Optimal Parameters of RF without Variable 'expense': %s\" % grid_rf.best_params_)\n",
    "print (\"Model Accuracy of RF without Variable 'expense': %s\" % grid_rf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
